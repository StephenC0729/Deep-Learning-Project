{"cells":[{"cell_type":"markdown","metadata":{"id":"uW_j7nZOXZr9"},"source":["# Assignment 2 - Task 2: Model Tuning\n","\n","This notebook tunes hyperparameters for two models using Keras Tuner and the existing processed splits:\n","- Deep Neural Network (tabular)\n","- GRU sequence model\n","\n","We search on the train/validation sets and keep the test set untouched for final evaluation.\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sKDqqusCXZr_","executionInfo":{"status":"ok","timestamp":1759231664052,"user_tz":-480,"elapsed":29453,"user":{"displayName":"Chiew Cheng","userId":"01365830263559312477"}},"outputId":"71b6aaf4-c92e-47d4-b58f-1520d03f777c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Keras Tuner not available; will use simple random search instead.\n","Mounted at /drive\n"]}],"source":["# Setup\n","from pathlib import Path\n","import os\n","import json\n","import random\n","\n","import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","# Try to import Keras Tuner; fall back to None\n","try:\n","    import keras_tuner as kt  # TF >=2.3\n","except Exception:\n","    try:\n","        import kerastuner as kt  # legacy\n","    except Exception:\n","        kt = None\n","        print('Keras Tuner not available; will use simple random search instead.')\n","\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.metrics import (\n","    mean_absolute_error,\n","    mean_absolute_percentage_error,\n","    mean_squared_error,\n","    r2_score,\n",")\n","import joblib\n","\n","# Reproducibility\n","RANDOM_SEED = 42\n","np.random.seed(RANDOM_SEED)\n","random.seed(RANDOM_SEED)\n","tf.random.set_seed(RANDOM_SEED)\n","\n","# Paths\n","from google.colab import drive\n","drive.mount('/drive')\n","DATA_DIR = Path('/drive/My Drive/Colab Notebooks/notebooks/data/processed')\n","MODELS_DIR = Path('/drive/My Drive/Colab Notebooks/notebooks/models/tuned')\n","ARTIFACTS_DIR = Path('/drive/My Drive/Colab Notebooks/notebooks/artifacts')\n","MODELS_DIR.mkdir(parents=True, exist_ok=True)\n","ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n","\n","AUTOTUNE = tf.data.AUTOTUNE\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1FPPUrfqXZsA","executionInfo":{"status":"ok","timestamp":1759231769464,"user_tz":-480,"elapsed":5346,"user":{"displayName":"Chiew Cheng","userId":"01365830263559312477"}},"outputId":"2bca20c0-ba9b-4c18-9dda-55ec051275d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Installed keras-tuner into current kernel.\n"]}],"source":["# Ensure keras-tuner is available in this kernel\n","if 'kt' in globals() and kt is None:\n","    import sys, subprocess\n","    try:\n","        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-U', 'keras-tuner'])\n","        import keras_tuner as kt  # retry\n","        print('Installed keras-tuner into current kernel.')\n","    except Exception as e:\n","        print('Failed to install keras-tuner:', e)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PHn5trSNXZsB","executionInfo":{"status":"ok","timestamp":1759231776458,"user_tz":-480,"elapsed":1600,"user":{"displayName":"Chiew Cheng","userId":"01365830263559312477"}},"outputId":"ed39e1a1-b5d0-4797-ea64-1796814e67bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shapes -> train: (44730, 9) val: (9884, 9) test: (9918, 9)\n"]}],"source":["# Load data\n","train_df = pd.read_csv(DATA_DIR / 'train.csv', parse_dates=['Month'])\n","val_df = pd.read_csv(DATA_DIR / 'val.csv', parse_dates=['Month'])\n","test_df = pd.read_csv(DATA_DIR / 'test.csv', parse_dates=['Month'])\n","\n","print('Shapes -> train:', train_df.shape, 'val:', val_df.shape, 'test:', test_df.shape)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rb0mwXwqXZsB","executionInfo":{"status":"ok","timestamp":1759231798881,"user_tz":-480,"elapsed":95,"user":{"displayName":"Chiew Cheng","userId":"01365830263559312477"}},"outputId":"b618e617-9c72-4034-b9ae-94e2830955ff"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/drive/My Drive/Colab Notebooks/notebooks/artifacts/year_scaler.joblib']"]},"metadata":{},"execution_count":4}],"source":["# Shared feature engineering\n","\n","def add_time_features(df: pd.DataFrame) -> pd.DataFrame:\n","    df['MonthSin'] = np.sin(2 * np.pi * df['MonthNum'] / 12.0)\n","    df['MonthCos'] = np.cos(2 * np.pi * df['MonthNum'] / 12.0)\n","    return df\n","\n","for frame in (train_df, val_df, test_df):\n","    add_time_features(frame)\n","\n","all_series_ids = pd.concat([\n","    train_df['Series ID'], val_df['Series ID'], test_df['Series ID']\n","], axis=0).unique()\n","series_ids = sorted(all_series_ids)\n","series_index = {sid: idx for idx, sid in enumerate(series_ids)}\n","max_den = max(len(series_ids) - 1, 1)\n","for frame in (train_df, val_df, test_df):\n","    frame['SeriesIndex'] = frame['Series ID'].map(series_index).astype('float32')\n","    frame['SeriesIndexNorm'] = frame['SeriesIndex'] / max_den\n","\n","# Scalers for sequence features\n","turnover_scaler = StandardScaler()\n","year_scaler = StandardScaler()\n","\n","train_df['TurnoverScaled'] = turnover_scaler.fit_transform(train_df[['Turnover']])\n","val_df['TurnoverScaled'] = turnover_scaler.transform(val_df[['Turnover']])\n","test_df['TurnoverScaled'] = turnover_scaler.transform(test_df[['Turnover']])\n","\n","train_df['YearScaled'] = year_scaler.fit_transform(train_df[['Year']])\n","val_df['YearScaled'] = year_scaler.transform(val_df[['Year']])\n","test_df['YearScaled'] = year_scaler.transform(test_df[['Year']])\n","\n","# Persist scalers for reuse\n","joblib.dump(turnover_scaler, ARTIFACTS_DIR / 'turnover_scaler.joblib')\n","joblib.dump(year_scaler, ARTIFACTS_DIR / 'year_scaler.joblib')\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zV51TXwWXZsB","executionInfo":{"status":"ok","timestamp":1759231800924,"user_tz":-480,"elapsed":295,"user":{"displayName":"Chiew Cheng","userId":"01365830263559312477"}},"outputId":"41d07aaa-0e31-45cd-be58-4a031da880d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["DNN input dim: 183\n"]}],"source":["# Tabular DNN inputs\n","\n","target_col = 'Turnover'\n","dnn_categorical_cols = ['State', 'Industry', 'Series ID']\n","dnn_numeric_cols = ['Year', 'MonthNum', 'Quarter', 'MonthSin', 'MonthCos']\n","dnn_feature_cols = dnn_categorical_cols + dnn_numeric_cols\n","\n","# Preprocessor\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('categorical', OneHotEncoder(handle_unknown='ignore', sparse_output=False), dnn_categorical_cols),\n","        ('numeric', StandardScaler(), dnn_numeric_cols),\n","    ]\n",")\n","\n","X_train_dnn = preprocessor.fit_transform(train_df[dnn_feature_cols]).astype(np.float32)\n","X_val_dnn = preprocessor.transform(val_df[dnn_feature_cols]).astype(np.float32)\n","X_test_dnn = preprocessor.transform(test_df[dnn_feature_cols]).astype(np.float32)\n","\n","y_train = train_df[target_col].to_numpy(np.float32)\n","y_val = val_df[target_col].to_numpy(np.float32)\n","y_test = test_df[target_col].to_numpy(np.float32)\n","\n","# Save preprocessor\n","joblib.dump(preprocessor, ARTIFACTS_DIR / 'dnn_preprocessor.joblib')\n","\n","print('DNN input dim:', X_train_dnn.shape[1])\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NmtDFQZrXZsC","executionInfo":{"status":"ok","timestamp":1759231803541,"user_tz":-480,"elapsed":760,"user":{"displayName":"Chiew Cheng","userId":"01365830263559312477"}},"outputId":"ec99fa31-4e36-4b54-cc10-c9eae95c4a0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Seq shapes -> train: (42930, 12, 5) val: (8060, 12, 5) test: (8140, 12, 5)\n"]}],"source":["# Sequence data builders (reuse from Task 1)\n","WINDOW_SIZE_DEFAULT = 12\n","HORIZON = 1\n","seq_feature_cols = ['TurnoverScaled', 'MonthSin', 'MonthCos', 'YearScaled', 'SeriesIndexNorm']\n","seq_target_col = 'TurnoverScaled'\n","\n","def build_sequence_arrays(df: pd.DataFrame, feature_cols: list[str], target_col: str, window: int, horizon: int):\n","    sequences, targets, actuals = [], [], []\n","    for _, group in df.groupby('Series ID'):\n","        group = group.sort_values('Month')\n","        feat = group[feature_cols].to_numpy(np.float32)\n","        targ = group[target_col].to_numpy(np.float32)\n","        actual = group['Turnover'].to_numpy(np.float32)\n","        n = len(group) - window - horizon + 1\n","        if n <= 0:\n","            continue\n","        for i in range(n):\n","            sequences.append(feat[i:i+window])\n","            targets.append(targ[i+window:i+window+horizon])\n","            actuals.append(actual[i+window:i+window+horizon])\n","    if not sequences:\n","        return (\n","            np.empty((0, window, len(feature_cols)), dtype=np.float32),\n","            np.empty((0, horizon), dtype=np.float32),\n","            np.empty((0, horizon), dtype=np.float32),\n","        )\n","    return np.stack(sequences), np.stack(targets), np.stack(actuals)\n","\n","X_seq_train, y_seq_train, _ = build_sequence_arrays(train_df, seq_feature_cols, seq_target_col, WINDOW_SIZE_DEFAULT, HORIZON)\n","X_seq_val, y_seq_val, _ = build_sequence_arrays(val_df, seq_feature_cols, seq_target_col, WINDOW_SIZE_DEFAULT, HORIZON)\n","X_seq_test, y_seq_test_scaled, y_seq_test_actual = build_sequence_arrays(test_df, seq_feature_cols, seq_target_col, WINDOW_SIZE_DEFAULT, HORIZON)\n","\n","print('Seq shapes -> train:', X_seq_train.shape, 'val:', X_seq_val.shape, 'test:', X_seq_test.shape)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ZWHLcmT3XZsC","executionInfo":{"status":"ok","timestamp":1759231810189,"user_tz":-480,"elapsed":16,"user":{"displayName":"Chiew Cheng","userId":"01365830263559312477"}}},"outputs":[],"source":["# Utilities\n","\n","def make_datasets(X_train, y_train, X_val, y_val, batch_size):\n","    train_ds = (\n","        tf.data.Dataset.from_tensor_slices((X_train, y_train))\n","        .shuffle(buffer_size=len(X_train), seed=RANDOM_SEED, reshuffle_each_iteration=True)\n","        .batch(batch_size)\n","        .prefetch(AUTOTUNE)\n","    )\n","    val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size).prefetch(AUTOTUNE)\n","    return train_ds, val_ds\n","\n","\n","def compute_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> dict:\n","    mse = mean_squared_error(y_true, y_pred)\n","    rmse = float(np.sqrt(mse))\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mape = mean_absolute_percentage_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'R2': r2}\n","\n","\n","def save_json(obj: dict, path: Path):\n","    with open(path, 'w', encoding='utf-8') as f:\n","        json.dump(obj, f, indent=2)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"LaW3aEjxXZsC","executionInfo":{"status":"ok","timestamp":1759231813431,"user_tz":-480,"elapsed":30,"user":{"displayName":"Chiew Cheng","userId":"01365830263559312477"}}},"outputs":[],"source":["# Tuning search spaces\n","\n","MAX_EPOCHS = 80\n","DNN_TRIALS = 30\n","GRU_TRIALS = 30\n","\n","\n","def build_dnn_model_hp(input_dim: int, hp: 'kt.HyperParameters') -> keras.Model:\n","    inputs = keras.Input(shape=(input_dim,), name='tabular_features')\n","    x = inputs\n","\n","    num_layers = hp.Int('dnn_num_layers', 2, 4)\n","    for i in range(num_layers):\n","        units = hp.Int(f'dnn_units_{i}', min_value=64, max_value=512, step=64)\n","        x = keras.layers.Dense(units, activation=hp.Choice('dnn_activation', ['relu', 'gelu']))(x)\n","        if hp.Boolean('dnn_batchnorm', default=True):\n","            x = keras.layers.BatchNormalization()(x)\n","        dropout = hp.Float('dnn_dropout', 0.0, 0.5, step=0.1)\n","        if dropout > 0:\n","            x = keras.layers.Dropout(dropout)(x)\n","    outputs = keras.layers.Dense(1, name='turnover')(x)\n","\n","    model = keras.Model(inputs=inputs, outputs=outputs, name='DNN_Tuned')\n","    lr = hp.Float('dnn_lr', 1e-4, 5e-3, sampling='log')\n","    wd = hp.Float('dnn_weight_decay', 1e-6, 1e-3, sampling='log')\n","    optimizer = keras.optimizers.Adam(learning_rate=lr)\n","    model.compile(\n","        optimizer=optimizer,\n","        loss='mse',\n","        metrics=[\n","            keras.metrics.MeanSquaredError(name='mse'),\n","            keras.metrics.RootMeanSquaredError(name='rmse'),\n","            keras.metrics.MeanAbsoluteError(name='mae'),\n","            keras.metrics.MeanAbsolutePercentageError(name='mape'),\n","        ],\n","    )\n","    return model\n","\n","\n","def build_gru_model_hp(window: int, feature_dim: int, horizon: int, hp: 'kt.HyperParameters') -> keras.Model:\n","    inputs = keras.Input(shape=(window, feature_dim), name='sequence_features')\n","    x = inputs\n","\n","    num_layers = hp.Int('gru_num_layers', 1, 2)\n","    units1 = hp.Int('gru_units1', 64, 256, step=64)\n","    x = keras.layers.GRU(units1, return_sequences=(num_layers > 1), kernel_initializer='glorot_uniform')(x)\n","    if hp.Boolean('gru_layernorm', default=True):\n","        x = keras.layers.LayerNormalization()(x)\n","    drop1 = hp.Float('gru_dropout1', 0.0, 0.5, step=0.1)\n","    if drop1 > 0:\n","        x = keras.layers.Dropout(drop1)(x)\n","\n","    if num_layers > 1:\n","        units2 = hp.Int('gru_units2', 64, 256, step=64)\n","        x = keras.layers.GRU(units2, return_sequences=False, kernel_initializer='glorot_uniform')(x)\n","        drop2 = hp.Float('gru_dropout2', 0.0, 0.5, step=0.1)\n","        if drop2 > 0:\n","            x = keras.layers.Dropout(drop2)(x)\n","\n","    outputs = keras.layers.Dense(horizon, kernel_initializer='glorot_uniform', name='scaled_turnover')(x)\n","\n","    model = keras.Model(inputs=inputs, outputs=outputs, name='GRU_Tuned')\n","    lr = hp.Float('gru_lr', 1e-4, 5e-3, sampling='log')\n","    optimizer = keras.optimizers.Adam(learning_rate=lr)\n","    model.compile(\n","        optimizer=optimizer,\n","        loss='mse',\n","        metrics=[\n","            keras.metrics.MeanSquaredError(name='mse'),\n","            keras.metrics.RootMeanSquaredError(name='rmse'),\n","            keras.metrics.MeanAbsoluteError(name='mae'),\n","            keras.metrics.MeanAbsolutePercentageError(name='mape'),\n","        ],\n","    )\n","    return model\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mrJw38TgXZsD","executionInfo":{"status":"ok","timestamp":1759235627085,"user_tz":-480,"elapsed":3789237,"user":{"displayName":"Chiew Cheng","userId":"01365830263559312477"}},"outputId":"690b8071-d851-44e6-8a1e-f44a545a503f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 30 Complete [00h 02m 14s]\n","val_loss: 3376.398681640625\n","\n","Best val_loss So Far: 2057.726318359375\n","Total elapsed time: 01h 00m 35s\n","Epoch 1/80\n","175/175 - 5s - 31ms/step - loss: 9893.1016 - mae: 44.0844 - mape: 104.1819 - mse: 9893.1016 - rmse: 99.4641 - val_loss: 6911.6543 - val_mae: 52.0348 - val_mape: 47.8921 - val_mse: 6911.6543 - val_rmse: 83.1364 - learning_rate: 0.0029\n","Epoch 2/80\n","175/175 - 3s - 19ms/step - loss: 456.6261 - mae: 12.6088 - mape: 28.9106 - mse: 456.6261 - rmse: 21.3688 - val_loss: 5297.1831 - val_mae: 47.5359 - val_mape: 38.7484 - val_mse: 5297.1831 - val_rmse: 72.7818 - learning_rate: 0.0029\n","Epoch 3/80\n","175/175 - 5s - 29ms/step - loss: 333.2637 - mae: 10.1928 - mape: 18.8212 - mse: 333.2637 - rmse: 18.2555 - val_loss: 4843.5020 - val_mae: 43.8136 - val_mape: 33.7616 - val_mse: 4843.5020 - val_rmse: 69.5953 - learning_rate: 0.0029\n","Epoch 4/80\n","175/175 - 3s - 18ms/step - loss: 290.6684 - mae: 9.4815 - mape: 16.8917 - mse: 290.6684 - rmse: 17.0490 - val_loss: 3980.5718 - val_mae: 40.3113 - val_mape: 35.8076 - val_mse: 3980.5718 - val_rmse: 63.0918 - learning_rate: 0.0029\n","Epoch 5/80\n","175/175 - 3s - 19ms/step - loss: 279.1714 - mae: 9.1947 - mape: 15.8014 - mse: 279.1714 - rmse: 16.7084 - val_loss: 3528.2488 - val_mae: 35.0528 - val_mape: 26.3808 - val_mse: 3528.2488 - val_rmse: 59.3991 - learning_rate: 0.0029\n","Epoch 6/80\n","175/175 - 6s - 32ms/step - loss: 256.5627 - mae: 8.7710 - mape: 14.4438 - mse: 256.5627 - rmse: 16.0176 - val_loss: 3885.5735 - val_mae: 37.7331 - val_mape: 35.5019 - val_mse: 3885.5735 - val_rmse: 62.3344 - learning_rate: 0.0029\n","Epoch 7/80\n","175/175 - 3s - 17ms/step - loss: 238.1850 - mae: 8.5430 - mape: 14.2409 - mse: 238.1850 - rmse: 15.4332 - val_loss: 2806.7837 - val_mae: 30.7965 - val_mape: 23.6333 - val_mse: 2806.7837 - val_rmse: 52.9791 - learning_rate: 0.0029\n","Epoch 8/80\n","175/175 - 3s - 17ms/step - loss: 208.0347 - mae: 7.9745 - mape: 13.3001 - mse: 208.0347 - rmse: 14.4234 - val_loss: 3132.0479 - val_mae: 33.0838 - val_mape: 24.1498 - val_mse: 3132.0479 - val_rmse: 55.9647 - learning_rate: 0.0029\n","Epoch 9/80\n","175/175 - 4s - 22ms/step - loss: 227.0903 - mae: 8.2605 - mape: 13.3300 - mse: 227.0903 - rmse: 15.0695 - val_loss: 2737.7393 - val_mae: 30.9391 - val_mape: 23.7976 - val_mse: 2737.7393 - val_rmse: 52.3234 - learning_rate: 0.0029\n","Epoch 10/80\n","175/175 - 4s - 22ms/step - loss: 202.1919 - mae: 7.5786 - mape: 11.8650 - mse: 202.1919 - rmse: 14.2194 - val_loss: 2532.5337 - val_mae: 29.9914 - val_mape: 27.1732 - val_mse: 2532.5337 - val_rmse: 50.3243 - learning_rate: 0.0029\n","Epoch 11/80\n","175/175 - 3s - 18ms/step - loss: 191.2820 - mae: 7.5875 - mape: 12.4373 - mse: 191.2820 - rmse: 13.8305 - val_loss: 2574.5913 - val_mae: 30.2131 - val_mape: 26.1275 - val_mse: 2574.5913 - val_rmse: 50.7404 - learning_rate: 0.0029\n","Epoch 12/80\n","175/175 - 3s - 17ms/step - loss: 186.9513 - mae: 7.4420 - mape: 11.5565 - mse: 186.9513 - rmse: 13.6730 - val_loss: 2681.6355 - val_mae: 30.3787 - val_mape: 23.0647 - val_mse: 2681.6355 - val_rmse: 51.7845 - learning_rate: 0.0029\n","Epoch 13/80\n","175/175 - 4s - 22ms/step - loss: 183.0785 - mae: 7.3546 - mape: 11.4038 - mse: 183.0785 - rmse: 13.5306 - val_loss: 2241.0493 - val_mae: 28.1884 - val_mape: 23.6401 - val_mse: 2241.0493 - val_rmse: 47.3397 - learning_rate: 0.0029\n","Epoch 14/80\n","175/175 - 4s - 23ms/step - loss: 170.5572 - mae: 7.1827 - mape: 11.3760 - mse: 170.5572 - rmse: 13.0598 - val_loss: 2395.4084 - val_mae: 30.0725 - val_mape: 27.0230 - val_mse: 2395.4084 - val_rmse: 48.9429 - learning_rate: 0.0029\n","Epoch 15/80\n","175/175 - 3s - 17ms/step - loss: 160.0833 - mae: 6.9216 - mape: 10.9022 - mse: 160.0833 - rmse: 12.6524 - val_loss: 2503.8625 - val_mae: 29.7502 - val_mape: 22.9542 - val_mse: 2503.8625 - val_rmse: 50.0386 - learning_rate: 0.0029\n","Epoch 16/80\n","175/175 - 3s - 18ms/step - loss: 155.8000 - mae: 6.7923 - mape: 10.4372 - mse: 155.8000 - rmse: 12.4820 - val_loss: 2628.7644 - val_mae: 29.8619 - val_mape: 21.4993 - val_mse: 2628.7644 - val_rmse: 51.2715 - learning_rate: 0.0029\n","Epoch 17/80\n","175/175 - 4s - 23ms/step - loss: 184.4552 - mae: 7.4129 - mape: 12.0870 - mse: 184.4552 - rmse: 13.5814 - val_loss: 2331.0027 - val_mae: 30.5926 - val_mape: 29.4650 - val_mse: 2331.0027 - val_rmse: 48.2805 - learning_rate: 0.0029\n","Epoch 18/80\n","175/175 - 4s - 25ms/step - loss: 164.5712 - mae: 7.0000 - mape: 10.8261 - mse: 164.5712 - rmse: 12.8285 - val_loss: 2720.2893 - val_mae: 31.6628 - val_mape: 25.6257 - val_mse: 2720.2893 - val_rmse: 52.1564 - learning_rate: 0.0029\n","Epoch 19/80\n","175/175 - 5s - 29ms/step - loss: 115.6602 - mae: 5.7753 - mape: 8.4726 - mse: 115.6602 - rmse: 10.7545 - val_loss: 2429.4768 - val_mae: 29.7435 - val_mape: 24.0321 - val_mse: 2429.4768 - val_rmse: 49.2897 - learning_rate: 0.0014\n","Epoch 20/80\n","175/175 - 7s - 37ms/step - loss: 105.8674 - mae: 5.5754 - mape: 8.2609 - mse: 105.8674 - rmse: 10.2892 - val_loss: 2261.4863 - val_mae: 28.7336 - val_mape: 22.4531 - val_mse: 2261.4863 - val_rmse: 47.5551 - learning_rate: 0.0014\n","Epoch 21/80\n","175/175 - 4s - 21ms/step - loss: 109.8139 - mae: 5.6826 - mape: 8.4780 - mse: 109.8139 - rmse: 10.4792 - val_loss: 2316.0593 - val_mae: 29.2815 - val_mape: 26.2808 - val_mse: 2316.0593 - val_rmse: 48.1255 - learning_rate: 0.0014\n","Epoch 22/80\n","175/175 - 3s - 18ms/step - loss: 108.9136 - mae: 5.6150 - mape: 8.2190 - mse: 108.9136 - rmse: 10.4362 - val_loss: 2316.4973 - val_mae: 29.2464 - val_mape: 25.9611 - val_mse: 2316.4973 - val_rmse: 48.1300 - learning_rate: 0.0014\n","Epoch 23/80\n","175/175 - 7s - 40ms/step - loss: 104.1595 - mae: 5.4898 - mape: 8.0341 - mse: 104.1595 - rmse: 10.2059 - val_loss: 2211.9199 - val_mae: 29.3277 - val_mape: 27.1596 - val_mse: 2211.9199 - val_rmse: 47.0311 - learning_rate: 0.0014\n","Epoch 24/80\n","175/175 - 3s - 18ms/step - loss: 107.1921 - mae: 5.5857 - mape: 8.2153 - mse: 107.1921 - rmse: 10.3534 - val_loss: 2304.5476 - val_mae: 29.7406 - val_mape: 25.6900 - val_mse: 2304.5476 - val_rmse: 48.0057 - learning_rate: 0.0014\n","Epoch 25/80\n","175/175 - 3s - 18ms/step - loss: 110.8124 - mae: 5.6662 - mape: 8.2024 - mse: 110.8124 - rmse: 10.5267 - val_loss: 2126.8564 - val_mae: 28.8054 - val_mape: 25.3138 - val_mse: 2126.8564 - val_rmse: 46.1179 - learning_rate: 0.0014\n","Epoch 26/80\n","175/175 - 4s - 21ms/step - loss: 108.1987 - mae: 5.6003 - mape: 8.2115 - mse: 108.1987 - rmse: 10.4019 - val_loss: 2821.1921 - val_mae: 31.3566 - val_mape: 24.0289 - val_mse: 2821.1921 - val_rmse: 53.1149 - learning_rate: 0.0014\n","Epoch 27/80\n","175/175 - 5s - 30ms/step - loss: 107.9028 - mae: 5.5710 - mape: 8.1975 - mse: 107.9028 - rmse: 10.3876 - val_loss: 2307.4480 - val_mae: 29.0745 - val_mape: 22.7840 - val_mse: 2307.4480 - val_rmse: 48.0359 - learning_rate: 0.0014\n","Epoch 28/80\n","175/175 - 3s - 19ms/step - loss: 105.9999 - mae: 5.5277 - mape: 7.9800 - mse: 105.9999 - rmse: 10.2956 - val_loss: 2077.8472 - val_mae: 27.9567 - val_mape: 23.2171 - val_mse: 2077.8472 - val_rmse: 45.5834 - learning_rate: 0.0014\n","Epoch 29/80\n","175/175 - 3s - 19ms/step - loss: 103.6714 - mae: 5.5507 - mape: 8.1319 - mse: 103.6714 - rmse: 10.1819 - val_loss: 2205.8501 - val_mae: 28.8176 - val_mape: 26.4099 - val_mse: 2205.8501 - val_rmse: 46.9665 - learning_rate: 0.0014\n","Epoch 30/80\n","175/175 - 5s - 27ms/step - loss: 103.9839 - mae: 5.5299 - mape: 8.1717 - mse: 103.9839 - rmse: 10.1973 - val_loss: 2197.2795 - val_mae: 28.4429 - val_mape: 23.3586 - val_mse: 2197.2795 - val_rmse: 46.8751 - learning_rate: 0.0014\n","Epoch 31/80\n","175/175 - 3s - 19ms/step - loss: 98.5117 - mae: 5.3587 - mape: 7.8154 - mse: 98.5117 - rmse: 9.9253 - val_loss: 2205.3489 - val_mae: 28.4804 - val_mape: 25.7558 - val_mse: 2205.3489 - val_rmse: 46.9611 - learning_rate: 0.0014\n","Epoch 32/80\n","175/175 - 5s - 29ms/step - loss: 104.8636 - mae: 5.4769 - mape: 7.8380 - mse: 104.8636 - rmse: 10.2403 - val_loss: 2105.3020 - val_mae: 28.5131 - val_mape: 26.8852 - val_mse: 2105.3020 - val_rmse: 45.8836 - learning_rate: 0.0014\n","Epoch 33/80\n","175/175 - 4s - 25ms/step - loss: 101.8951 - mae: 5.4543 - mape: 7.9628 - mse: 101.8951 - rmse: 10.0943 - val_loss: 2154.2405 - val_mae: 28.0633 - val_mape: 23.9310 - val_mse: 2154.2405 - val_rmse: 46.4138 - learning_rate: 0.0014\n","Epoch 34/80\n","175/175 - 4s - 21ms/step - loss: 80.9671 - mae: 4.8550 - mape: 7.0091 - mse: 80.9671 - rmse: 8.9982 - val_loss: 2083.4653 - val_mae: 28.1755 - val_mape: 26.0709 - val_mse: 2083.4653 - val_rmse: 45.6450 - learning_rate: 7.2209e-04\n","Epoch 35/80\n","175/175 - 5s - 29ms/step - loss: 80.4375 - mae: 4.8056 - mape: 6.8135 - mse: 80.4375 - rmse: 8.9687 - val_loss: 2138.2241 - val_mae: 28.0575 - val_mape: 24.7647 - val_mse: 2138.2241 - val_rmse: 46.2409 - learning_rate: 7.2209e-04\n","Epoch 36/80\n","175/175 - 4s - 23ms/step - loss: 78.9501 - mae: 4.7702 - mape: 6.8044 - mse: 78.9501 - rmse: 8.8854 - val_loss: 2189.0015 - val_mae: 29.1378 - val_mape: 28.1726 - val_mse: 2189.0015 - val_rmse: 46.7868 - learning_rate: 7.2209e-04\n","Epoch 37/80\n","175/175 - 4s - 24ms/step - loss: 79.0367 - mae: 4.7464 - mape: 6.7083 - mse: 79.0367 - rmse: 8.8903 - val_loss: 2161.5708 - val_mae: 28.5547 - val_mape: 26.7402 - val_mse: 2161.5708 - val_rmse: 46.4927 - learning_rate: 7.2209e-04\n","Epoch 38/80\n","175/175 - 3s - 18ms/step - loss: 77.7881 - mae: 4.7789 - mape: 6.8842 - mse: 77.7881 - rmse: 8.8198 - val_loss: 2153.3354 - val_mae: 28.4141 - val_mape: 25.1790 - val_mse: 2153.3354 - val_rmse: 46.4040 - learning_rate: 7.2209e-04\n","DNN tuned test metrics: {'MSE': 7674.50439453125, 'RMSE': 87.60424872419858, 'MAE': 60.4646110534668, 'MAPE': 0.6079199314117432, 'R2': 0.9707192182540894}\n"]}],"source":["# Run Keras Tuner for DNN (BayesianOptimization with explicit max_trials)\n","\n","if kt is None:\n","    print('Skip Keras Tuner for DNN since not available.')\n","else:\n","    tuner = kt.BayesianOptimization(\n","        hypermodel=lambda hp: build_dnn_model_hp(X_train_dnn.shape[1], hp),\n","        objective=kt.Objective('val_loss', direction='min'),\n","        max_trials=DNN_TRIALS,\n","        seed=RANDOM_SEED,\n","        directory=str(ARTIFACTS_DIR / 'kt_dnn'),\n","        project_name='dnn_bayes',\n","        overwrite=True,\n","    )\n","\n","    batch_size = 256\n","    train_ds, val_ds = make_datasets(X_train_dnn, y_train, X_val_dnn, y_val, batch_size)\n","\n","    stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","    reduce = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n","\n","    tuner.search(\n","        train_ds,\n","        epochs=MAX_EPOCHS,\n","        validation_data=val_ds,\n","        callbacks=[stop, reduce],\n","        verbose=2,\n","    )\n","\n","    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","    save_json(best_hps.values, ARTIFACTS_DIR / 'dnn_best_hyperparameters.json')\n","\n","    best_model = tuner.hypermodel.build(best_hps)\n","    history = best_model.fit(\n","        train_ds,\n","        validation_data=val_ds,\n","        epochs=MAX_EPOCHS,\n","        callbacks=[stop, reduce],\n","        verbose=2,\n","    )\n","\n","    # Evaluate and save\n","    dnn_eval = best_model.evaluate(tf.data.Dataset.from_tensor_slices((X_test_dnn, y_test)).batch(256), return_dict=True, verbose=0)\n","    dnn_preds = best_model.predict(X_test_dnn, batch_size=256, verbose=0).squeeze()\n","    dnn_metrics = compute_metrics(y_test, dnn_preds)\n","    print('DNN tuned test metrics:', dnn_metrics)\n","\n","    best_model.save(MODELS_DIR / 'dnn_tuned.keras')\n","    save_json({'val_history': history.history, 'test_metrics': dnn_metrics}, ARTIFACTS_DIR / 'dnn_tuned_metrics.json')\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kwnO7ujeXZsD","executionInfo":{"status":"ok","timestamp":1759254369093,"user_tz":-480,"elapsed":8214230,"user":{"displayName":"Chiew Cheng","userId":"01365830263559312477"}},"outputId":"84b7a3b3-7b3d-4d9f-ef18-b259c0b5a50e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 12 Complete [00h 09m 46s]\n","val_loss: 0.026431001722812653\n","\n","Best val_loss So Far: 0.008686594665050507\n","Total elapsed time: 02h 16m 45s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n"]},{"output_type":"stream","name":"stdout","text":["GRU tuned test metrics: {'MSE': 1094.508056640625, 'RMSE': 33.08335014233935, 'MAE': 12.855664253234863, 'MAPE': 0.10264773666858673, 'R2': 0.9959864020347595}\n"]}],"source":["# Run Keras Tuner for GRU (faster settings: fewer trials/epochs, cached pipeline, no retrain)\n","\n","if kt is None:\n","    print('Skip Keras Tuner for GRU since not available.')\n","else:\n","    # Reduce total search effort for speed\n","    fast_trials = min(12, GRU_TRIALS)\n","    fast_epochs = min(30, MAX_EPOCHS)\n","\n","    tuner_gru = kt.BayesianOptimization(\n","        hypermodel=lambda hp: build_gru_model_hp(WINDOW_SIZE_DEFAULT, X_seq_train.shape[2], HORIZON, hp),\n","        objective=kt.Objective('val_loss', direction='min'),\n","        max_trials=fast_trials,\n","        seed=RANDOM_SEED,\n","        directory=str(ARTIFACTS_DIR / 'kt_gru'),\n","        project_name='gru_bayes',\n","        overwrite=True,\n","    )\n","\n","    # Choose batch size based on device capability\n","    try:\n","        has_gpu = len(tf.config.list_physical_devices('GPU')) > 0\n","    except Exception:\n","        has_gpu = False\n","    batch_size = 256 if has_gpu else 128\n","\n","    # Faster tf.data pipeline with cache + prefetch\n","    def make_fast_seq_datasets(Xtr, ytr, Xva, yva, bs):\n","        train = (tf.data.Dataset.from_tensor_slices((Xtr, ytr))\n","                 .shuffle(min(len(Xtr), 10000), seed=RANDOM_SEED, reshuffle_each_iteration=True)\n","                 .batch(bs)\n","                 .cache()\n","                 .prefetch(AUTOTUNE))\n","        val = (tf.data.Dataset.from_tensor_slices((Xva, yva))\n","               .batch(bs)\n","               .cache()\n","               .prefetch(AUTOTUNE))\n","        return train, val\n","\n","    train_ds, val_ds = make_fast_seq_datasets(X_seq_train, y_seq_train, X_seq_val, y_seq_val, batch_size)\n","\n","    # Tighter early stopping to cut epochs earlier\n","    stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","    reduce = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5)\n","\n","    tuner_gru.search(\n","        train_ds,\n","        epochs=fast_epochs,\n","        validation_data=val_ds,\n","        callbacks=[stop, reduce],\n","        verbose=2,\n","    )\n","\n","    # Pick best hyperparameters\n","    best_hps = tuner_gru.get_best_hyperparameters(num_trials=1)[0]\n","    save_json(best_hps.values, ARTIFACTS_DIR / 'gru_best_hyperparameters.json')\n","\n","    # Reuse the trained best model from the search to avoid a full second fit\n","    best_model = tuner_gru.get_best_models(num_models=1)[0]\n","\n","    # Evaluate and save\n","    test_seq_ds = (tf.data.Dataset\n","                   .from_tensor_slices((X_seq_test, y_seq_test_scaled))\n","                   .batch(batch_size)\n","                   .cache()\n","                   .prefetch(AUTOTUNE))\n","    gru_eval = best_model.evaluate(test_seq_ds, return_dict=True, verbose=0)\n","    preds_scaled = best_model.predict(X_seq_test, batch_size=batch_size, verbose=0)\n","    preds = turnover_scaler.inverse_transform(preds_scaled)\n","    y_true = y_seq_test_actual.squeeze(axis=-1)\n","    y_pred = preds.squeeze(axis=-1)\n","    gru_metrics = compute_metrics(y_true, y_pred)\n","    print('GRU tuned test metrics:', gru_metrics)\n","\n","    best_model.save(MODELS_DIR / 'gru_tuned.keras')\n","    # No history when skipping retrain; log eval metrics instead\n","    save_json({'val_best_hps': best_hps.values, 'test_metrics': gru_metrics, 'eval': gru_eval}, ARTIFACTS_DIR / 'gru_tuned_metrics.json')\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}